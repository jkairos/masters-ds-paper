\section{A Technique for Debugging A Distributed R-Tree}
\label{sec:rdebug}

	Spatial index debugging is a big challenge in a distributed R-Tree and this section describes a new technique RDebug, which allows debugging the index building of an R-Tree.
	
	The R-tree index building follows a top-down approach, in other words, the index is always built from root to leaves. Debugging the index reliability as the index is built is a non-trivial task, and the aim of this paper is to show a technique for index debugging after it has been created. Common challenges when working with an R-Tree are: i) Reliability of the nodes replicas of the R-Tree, ii) ensure that the MBR of the parent nodes intersect the MBR of their children, iii) the existence of duplicated nodes or being referenced by more than one parent node, and iv) if the value M and m of the nodes are compliant with the R-Tree descriptions as shown in Section \ref{sec:spatial_dist}. Furthermore, it is possible to access index data to help in its optimization as dead space and overlapping area.

	Algorithm \ref{alg:rdebug} shows the RDebug technique for debugging the distributed spatial index, using the index structure itself. The algorithm has two steps:
1) The algorithm processing is similar to the search in an R-Tree; 2) The algorithm does the inverse of a search in an R-Tree appending information to the distributed index.

	The first step, called S1 [Search sub-trees] (lines 1 - 11), the Algorithm \ref{alg:rdebug} traverses every node of the R-Tree starting from the root node to the leaves. Its purpose is to spread the debugging algorithm. The first request is sent to any server, which stores a replica of the root node.

	If the node $T$ is not a leaf (lines 2 - 8), then the number of children entries is stored to control the number of expected answers to this node in the second step of the algorithm. This information is stored in a shared memory accessed by all servers with a replica of $T$. Lines 4 -7, show that for every entry $E$ in the node, a message is sent (continuing step S1) to any server that holds a replica of the child node of $E$, carrying on the first step in the children nodes. If the node is a leaf, the second step, named S2 [Aggregation] is started.

	Second step aim (lines 12 - 41) is to aggregate the information used for future debugging. This step receives the debugging information of every child node of $T$. Therefore, for a given node $T$ with $n$ children, the second step is invoked $n$ times in the node $T$.

	The index itself is used to aggregate this information, the computational resources of the cluster helps improve the debugging information aggregation time. The index reverse structure allows, besides of spanning the aggregation information processing, build the debugging aggregation information, as one node of the R-Tree is responsible to aggregate only the information of its children. 

	Line 13 verifies the consistency of $T$ in the servers that store any replica of $T$. Line 14 verifies the consistency of $M$ and $m$. Lines 16 and 17 calculate the dead space and overlapping area for each node of the R-tree. Those information help the insertion algorithm designer analyze the quality of the built index. Beside this, lines 18 - 22, we have information of the MBRs of each node for every entry of the node. This information can be used as an input to a tool capable of visualizing the index of the R-Tree.
	
	If the aggregation step is being executed in the leaves, then if  $T$ is the root node (lines 24 - 26), the node information are sent to the client application. IF $T$ is not the root node, in line 27, the information are sent to the parent node of $T$. If the aggregation step is in an internal node (lines 29 - 43), the algorithm aggregates the information of the children nodes. Line 29, the algorithm receives the information sent by the child node. Line 30, verifies if the MBR of the entry that points to the child node is indeed the same MBR sent by the child node.
	
	The information of the children nodes are stored in a shared memory, with concurrency control, by the replicas of $T$. Hence, line 31, those information are accessed from the shared memory. Line 32, adds the data processed from lines 29 and 30. Line 33, acquires the number of children nodes that sent debugging information in the shared memory of replicas $T$. This information is stored in the variable $count$ and $count$ is decremented to let the other replicas know.
	
	If every node has sent the answer, the variable count then will hold the value 0 and lines 35-39 are processed. If $T$ is the root node, then the information are sent to the client application, otherwise, those information are sent to the parent node of $T$. If the variable $count$ is greater than 0, then the client information are stored in the shared memory.	
		
\medskip
\begin{center}
\begin{minipage}{1\textwidth}
\begin{algorithm2e}[H]
\SetAlFnt{\small\sf}
 \DontPrintSemicolon
 \LinesNumbered
\SetAlgoLined
 \BlankLine
 \Entrada{$T$ reference to root node of R-Tree $tree$}
 \Saida{Debugging information about distributed R-Tree $tree$}
 \BlankLine
	
 S1 [Search subtrees]

\eIf{$T$ is not leaf}{
  store the number of child entries in each replica server of T\;
	
	\For{each entry $E$ in $T$} {
		$server \leftarrow $ choose one server, randomically,  that store one replica of $E$\;
		send msg to $server$ to process the node child of $E$ on step S1\;
	}
}
{
  verifiy the consistency of $T$ in others replicas\;
	Invoke step S2 [Aggregation]\;
}

S2 [Aggregation]

$replica\_consistency \Leftarrow$ verifiy the consistency of $T$ in others replicas\;
$node\_consistency \Leftarrow$	verify the consistency of $M$ and $m$ values of  $T$\;
add in $informations$: $replica\_consistency$ and $node\_consistency$\;

$overlap \Leftarrow$ overlap area of $T$\;
$dead\_area \Leftarrow$ dead area of $T$\;
$bound \Leftarrow$ MBR of $T$\;
$list \Leftarrow \emptyset$\;

\For{for each entry $E$ in $T$}{
	add the $MBR$ of $E$ in $list$\;
}

\eIf{$T$ is leaf}{
 \If{$T$ is root}{
		send response with R-Tree nodes information to app client\;
	}
	{
		send msg with $informations$ to parent of $T$\;
	}
}
{
	  $entry\_info \Leftarrow$ information sent by child node\;
    $mbr\_consistent \Leftarrow$ verify if the bound of the child node is equal to bound of entry of T that points to this child\;
		$informations \Leftarrow$ the child information stored on shared memory by replicas of $T$\;
    add in $informations$: $entries\_info$, and $mbr\_consistent$\;
		
		$count \Leftarrow$ retrieve the number of entries child which not sent a debugging response and decrement by 1 unit\;
		
    \eIf{$count$ == 0}{
        \eIf{$T$ is root}{
           send response with $informations$ to app client\;
        }
				{
				   send msg with $informations$ to parent of $T$\;
				}    
		}
		{
			store $informations$ on shared memory\;
		}
            
}
\caption{$RDebug(T)$ 
\label {alg:rdebug}}
\end{algorithm2e}
\end{minipage}
\end{center}

The algorithm \ref{alg:rdebug} was implemented in the DistGeo platform to collect the debugging information of the built distributed R-tree. Those information are used in the platform to find out indexing issues and to optimize the R-tree index for searching. Figure 4.1, shows a graphical tool created to visualize the structure of the distributed R-Tree index, using as the input the information generated by the distributed debugging algorithm in DistGeo platform.

[Colocar a Figura aqui!!]

With the aid of RDebug \ref{alg:rdebug} algorithm, it is possible debug the searching algorithms of an R-Tree. E.g: The Window Query algorithm shown on Section \ref{sub:spatialdata}. To tweak RDebug to Window Query, it is only needed add an window query in the first step and gather the aggregation information of the accessed nodes. Whereas, the algorithms that access diverse R-Trees, such as Spatial Join, need a deep change, as the algorithms can go through different paths.